{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, grid_transform=None, image_transform=None):\n",
    "        self.image_paths = image_paths.tolist()\n",
    "        self.image_transform = image_transform\n",
    "        self.grid_transform = grid_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Read the image\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = ImageOps.exif_transpose(Image.open(image_path).convert('RGB'))\n",
    "        if self.image_transform:\n",
    "            image = self.image_transform(image)\n",
    "        \n",
    "        # Create grid\n",
    "        _, height, width= image.shape\n",
    "        yx_grid = self._create_yx_grid(grid_size=(height, width))\n",
    "\n",
    "        assert len(yx_grid.shape) == len(image.shape)\n",
    "\n",
    "        if self.grid_transform is not None:\n",
    "            return self.grid_transform(yx_grid), image\n",
    "        else:\n",
    "            return yx_grid, image\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_yx_grid(grid_size):\n",
    "        \"\"\"\n",
    "        Creates mesh grid of normalised pixel coordinates based on matrix indexing convention\n",
    "        \"\"\"\n",
    "        h, w = grid_size\n",
    "        coords_i = np.linspace(0, 1, h, endpoint=False)\n",
    "        coords_j = np.linspace(0, 1, w, endpoint=False)\n",
    "        grid = torch.from_numpy(np.stack(np.meshgrid(coords_i, coords_j, indexing='ij'), axis=-1).astype('float32'))\n",
    "        return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, hr_path, grid_transform, n_splits=0):\n",
    "        super().__init__()\n",
    "        self.hr_path = hr_path\n",
    "        self.batch_size = 1\n",
    "        self.num_workers = 1\n",
    "        self.grid_transform = grid_transform\n",
    "        self.fold = 0\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Image transformations\n",
    "        self.image_transforms = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        self.train_dataset = ImageDataset(self.hr_path, self.grid_transform, self.image_transforms)\n",
    "\n",
    "    def set_fold(self, fold):\n",
    "        self.fold = fold\n",
    "        self.setup()  # Re-setup the datasets for the new fold\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fourier Encoded Features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFourierEncoding\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, num_input_channels: \u001b[38;5;28mint\u001b[39m, mapping_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m, scale: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(FourierEncoding, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m, in \u001b[0;36mFourierEncoding\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mapping_size \u001b[38;5;241m=\u001b[39m mapping_size\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(num_input_channels, mapping_size) \u001b[38;5;241m*\u001b[39m scale\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected 3D input (got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124mD input)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m     11\u001b[0m     height, width, channels \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Fourier Encoded Features\n",
    "class FourierEncoding(object):\n",
    "    def __init__(self, num_input_channels: int, mapping_size: int = 256, scale: int = 10):\n",
    "        super(FourierEncoding, self).__init__()\n",
    "        self._num_input_channels = num_input_channels\n",
    "        self._mapping_size = mapping_size\n",
    "        self._B = np.random.randn(num_input_channels, mapping_size) * scale\n",
    "\n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        assert len(x.shape) == 3, 'Expected 3D input (got {}D input)'.format(len(x.shape))\n",
    "        height, width, channels = x.shape\n",
    "        assert channels == self._num_input_channels, \\\n",
    "            \"Expected input to have {} channels (got {} channels)\".format(self._num_input_channels, channels)\n",
    "        # Make shape compatible for matmul with _B.\n",
    "        # From [H, W, C] to [(H*W), C].\n",
    "        x = x.reshape(height * width, channels)\n",
    "        x = x @ self._B\n",
    "        # From [(H*W), C] to [H, W, C]\n",
    "        x = x.reshape(height, width, self._mapping_size)\n",
    "        x = 2 * np.pi * x\n",
    "        return np.concatenate((np.sin(x), np.cos(x)), axis=-1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Wavelet Encoded Features\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mWaveletEncoding\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(WaveletEncoding, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m, in \u001b[0;36mWaveletEncoding\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28msuper\u001b[39m(WaveletEncoding, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Wavelet Encoded Features\n",
    "class WaveletEncoding(object):\n",
    "    def __init__(self):\n",
    "        super(WaveletEncoding, self).__init__()\n",
    "        \n",
    "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerfModel(nn.Module):\n",
    "    def __init__(self, input_shape, output_dim: int = 3, num_layers: int = 4, num_channels: int = 256):      \n",
    "        super(NerfModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.input_channels = input_shape[0]\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "\n",
    "        # Create the layers\n",
    "        for i in range(num_layers - 1):\n",
    "            self.conv_layers.append(nn.Conv2d(self.input_channels if i == 0 else num_channels, num_channels, kernel_size=1, padding=0))\n",
    "            self.conv_layers.append(nn.BatchNorm2d(num_channels))\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Conv2d(num_channels, output_dim, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.num_layers - 1):\n",
    "            x = F.relu(self.conv_layers[2*i](x))\n",
    "            x = self.conv_layers[2*i+1](x)\n",
    "        x = torch.sigmoid(self.output_layer(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerfTrainer(pl.LightningModule):\n",
    "    def __init__(self, input_shape, output_dim: int = 3, num_layers: int = 4, num_channels: int = 256, learning_rate: float = 1e-3):\n",
    "        super(NerfTrainer, self).__init__()\n",
    "        self.model = NerfModel(input_shape, output_dim, num_layers, num_channels)\n",
    "        self.loss_fn = torch.nn.MSELoss()\n",
    "        self.accuracy = Accuracy()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        acc = self.accuracy(y_hat, y)\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        self.log('test_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the original image\n",
    "# original_image = ImageOps.exif_transpose(Image.open('../data/hr_ground_truth.JPG'))\n",
    "\n",
    "# # Calculate the new resolution as 70% of the original size\n",
    "# new_resolution = (int(original_image.width * 0.7), int(original_image.height * 0.7))\n",
    "\n",
    "# # Resize the image to the new resolution\n",
    "# low_res_image = original_image.resize(new_resolution)\n",
    "# low_res_image.rotate(-90)\n",
    "\n",
    "# # Save the low-resolution image\n",
    "# low_res_image.save('path_to_save_low_res_image.jpg')\n",
    "\n",
    "# print(f\"Low-resolution image saved as 'path_to_save_low_res_image.jpg'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Transform\n",
    "grid_transform = FourierEncoding(num_input_channels=2, mapping_size=128, scale=10)\n",
    "\n",
    "# Inputs\n",
    "image_inputs = np.array([\n",
    "    '../data/low_res_train.jpg'\n",
    "])\n",
    "\n",
    "# Data Module Setup\n",
    "data_module = ImageDataModule(image_inputs, grid_transform)\n",
    "data_module.set_fold(0)\n",
    "\n",
    "# Trainer Setup\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the first batch\n",
    "first_batch = next(iter(data_module.train_dataloader()))\n",
    "\n",
    "# If the DataLoader returns a tuple (inputs, labels)\n",
    "inputs, labels = first_batch\n",
    "\n",
    "print(inputs.shape)  # Example: torch.Size([32, 3, 224, 224]) for a batch of 32 RGB images of size 224x224\n",
    "print(labels.shape)  # Example: torch.Size([32]) for a batch of 32 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Setup\n",
    "model = NerfModel(input_shape, output_dim=3, num_layers=4, num_channels=256)\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss', dirpath=f'{args.save_dir}/fold{fold}', filename=f'model-fold{fold}-{{epoch:02d}}-{{val_loss:.2f}}', save_top_k=1, mode='min')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,\n",
    "    callbacks=[early_stopping, checkpoint_callback, lr_monitor],\n",
    "    accelerator='gpu',\n",
    "    devices=1\n",
    ")\n",
    "\n",
    "# Training and Testing\n",
    "\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
